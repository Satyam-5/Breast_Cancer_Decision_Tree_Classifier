# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pmvZX3Z590C32aCmWzWnnNDq_3a3Km-E

# Breast cancer diagnosis using Decision Tree Classifier

###Import all the required libraries
"""

#importing libraries

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

"""### importing dataset"""

data = pd.read_csv('BreastCancerData.csv')

# ( Row, Column )

data.shape

# Columns names

data.columns

data.head()

# unique values of the column which is to be predicted by the classifier

data['diagnosis'].unique()

# Quick glimpse of tumor features (mean values) With respect to the diagnosis

data.groupby('diagnosis').mean()

# For visual comparisons of different diagnosis
# count number of : - benign, and malignant tumor in data

 # For Benign
count_bengin = (data['diagnosis']=='B').sum()
print("Bengin : ",count_bengin)

# For Malignant
count_malignant = (data['diagnosis']=='M').sum()
print("Malignant : ",count_malignant)

# Visualization of frequency of Diagnostic Outcomes in the  Dataset

plt.bar(['Bengin','Malignant'],[count_bengin,count_malignant],color=('blue','orange'))
plt.title('Frequency of Diagnostic Outcomes in the Dataset')
plt.ylabel('Frequency')
plt.show()

#taking care of missing data

(data.isna()).sum()

"""This shows that our data have no NULL values"""

# convert the dataset into numpy's ndarray (X and y)

y = data['diagnosis'].values
data.drop(['diagnosis', 'id'], inplace=True, axis=1)
X = data.values
print(type(X))
print(type(y))

"""Converting categorical data to numerical value"""

# taking care of categorical data

from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
y = labelencoder.fit_transform(y)

print(y[100:110])

"""We will use 75% of the data for training and 25% for testing"""

# spitting data into training and testing sets

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)

"""Now we will normalize/standardize our features before applying machine learning techniques.

We will use standeredscalar to normalize our data.

The idea behind StandardScaler is that it will transform your data such that its distribution will have a mean value 0 and standard deviation of 1. Given the distribution of the data, each value in the dataset will have the sample mean value subtracted, and then divided by the standard deviation of the whole dataset.
"""

# feature scaling

from sklearn.preprocessing import StandardScaler
Sc_X = StandardScaler()
X_train = Sc_X.fit_transform(X_train)
X_test = Sc_X.transform(X_test)

"""Accuracy_calculate function takes training data input , training data output and depth of Decision Tree Classifier
and returns the accuracy of our classification for the given depth value.
"""

def Accuracy_calculate(X_train,y_train,depth):
    # applying DecisionTreeClassifier model
    
    classifier = DecisionTreeClassifier(criterion="entropy", max_depth=depth)
    classifier.fit(X_train, y_train)
    
    #predicting values for test set
    
    y_pred = classifier.predict(X_test)
    
    #checking the accuracy
    Accuracy = accuracy_score(y_test,y_pred)
    Accuracy = Accuracy*100
    
    return Accuracy,depth

"""Just to check if our code is working or not, first we will check accuracy for any random value of max_depth"""

#for max_depth 3

Accuracy,depth = Accuracy_calculate(X_train,y_train,3)
print("Accuracy for max_depth 3 is : ",Accuracy)

"""For max_depth = 3 , our accuracy is above 95%

Now we will check accuracy for max_depth value between1 to 150 and calculate which value of max_depth gives highest accuracy
"""

#value of max_depth for better performance

Accuracy = 0

Accuracy_list = []
Depth_list = []
max_Accuracy = []
max_Depth = []

for i in range(1,151):
    x,y = Accuracy_calculate(X_train,y_train,i)
    Accuracy_list.append(x)
    Depth_list.append(y)
    if x > Accuracy:
        Accuracy = x
        depth = y

for i in range(1,150):
    if Accuracy_list[i] == Accuracy:
        max_Accuracy.append(Accuracy_list[i])
        max_Depth.append(Depth_list[i])
print("best value of max_depth is : ",depth," : with accuracy : ",Accuracy)

"""So, we got our best accuracy at max_depth 4

Now we will plot accuracy value for different max_depth value
"""

plt.figure(figsize=(20,10))
plt.plot(Depth_list,Accuracy_list,color='green',linestyle='dashed',marker='o',markerfacecolor='blue',markersize=5)
plt.plot(max_Depth,max_Accuracy,'ro')
plt.ylabel('Accuracy')
plt.xlabel('Depth')
plt.title('Accuracy vs Depth (Graphical Representation)')
plt.show()

"""We can see that their are more than 1 value of max_depth which gives highest accuracy"""

print(max_Depth)

"""For max_depth value 4, 63 and 89 we got our maximin accuracy"""

